{
  "metadata": {
    "name": "Spark Scala Антонов Даниил Николаевич",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// ------------------------ Тренажер Stepik \"PySpark - просто!\":----------------------------------------\n\n// https://stepik.org/course/113489/promo"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport org.apache.spark.sql.SparkSession\nval spark \u003d SparkSession.builder().master(\"local[*]\").appName(\"PySpark_Tutorial\").getOrCreate()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// val df \u003d spark.read.csv(\"/home/av/Downloads/stocks_price_final.csv\", sep\u003d\",\",    header\u003dtrue)\n// df.show()\n// .schema(final_struc)\nval df \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/home/av/Downloads/stocks_price_final.csv\")\ndf.show()\n    "
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val data \u003d df.limit(5)\ndata.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val df \u003d spark.read.csv(\"/home/av/Downloads/stocks_price_final.csv\")\r\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types._\r\n\r\n\r\nval data_schema \u003d Array(\r\n  StructField(\"_c0\", IntegerType, true),\r\n            StructField(\"symbol\", StringType, true),\r\n            StructField(\"data\", DateType, true),\r\n            StructField(\"open\", DoubleType, true),\r\n            StructField(\"high\", DoubleType, true),\r\n            StructField(\"low\", DoubleType, true),\r\n            StructField(\"close\", DoubleType, true),\r\n            StructField(\"volume\", IntegerType, true),\r\n            StructField(\"adjusted\", DoubleType, true),\r\n            StructField(\"market.cap\", StringType, true),\r\n            StructField(\"sector\", StringType, true),\r\n            StructField(\"industry\", StringType, true),\r\n            StructField(\"exchange\", StringType, true)\r\n  )"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val final_struc \u003dStructType(fields \u003d data_schema )\n\nval df \u003d spark.read.format(\"csv\").option(\"header\", \"true\").schema(final_struc ).load(\"/home/av/Downloads/stocks_price_final.csv\")\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val tst_josn \u003d spark.read.json(\"/home/av/Downloads/data.json\")\r\ntst_josn.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.schema"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.dtypes"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.take(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.first()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.columns"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.distinct().count()"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.distinct().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Операции ос столбцами\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.functions.lit\n\nval data_new \u003d data.withColumn(\"test_new\", lit(\"test\")) // lit - создает столбец test_new и заполняет его значениями \"test\"\n\ndata_new.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data_new.withColumnRenamed(\"test_new\",\"test_new_1\").show() // переименвание стобца\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data_new.drop(\"test_new\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val data_null \u003d data.withColumn(\"close\",     when(col(\"close\")\u003d\u003d\u003d62,null).otherwise(col(\"close\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data_null.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val data_null_new\u003ddata_null.withColumnRenamed(\"market.cap\",\"market_cap\")"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Работа с недостающими ззнаениями,\n// # Удаление строк с пропущенными значениями\ndata_null_new.na.drop().show()\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//mean(col(\"close\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// # Замена отсутствующих значений средним\nimport org.apache.spark.sql.functions.mean\n//data_null_new.na.fill(data_null_new.select(mean(data_null_new(\"close\"))).collect()[0][0]).show()\n\n// "
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// # Замена отсутствующих значений новыми\n//data_null_new.na.replace(51, 151).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val df \u003d spark.read.csv(\"/home/av/Downloads/stocks_price_final.csv\")\r\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// # Выбор одного столбца\r\ndata.select(\"sector\").show()\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// # Выбор нескольких столбцов\r\ndata.select(\"open\", \"close\",\"adjusted\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.filter( (col(\"open\") \u003e\u003d 54 )).show()\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\r\n\r\n//data.filter(data.select\"open\", \"close\",             f.when(col(\"adjusted\") \u003e\u003d 200.0, 1).otherwise(0).show()\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//data.select(\"open\", \"close\",       when(col(\"open\") \u003e\u003d 200.0, 1).otherwise(0)).show()"
    }
  ]
}